---
layout: default
title: 쿠버네티스 서비스(Service)와 디플로이먼트(Deployment)의 역할 및 실습 가이드
parent: 8월 19일
nav_order: 3
---

# 2025년 8월 19일 교육 내용

# 쿠버네티스

1) 쿠버네티스 서비스(Service)란? 📦
쿠버네티스 서비스는 동적으로 생성되고 사라지는 파드(Pod)들에게 안정적인 단일 네트워크 진입점(Entrypoint)을 제공하기 위한 핵심 오브젝트입니다.

파드는 언제든지 다시 시작되거나 다른 노드로 옮겨질 수 있어 IP 주소가 계속 바뀝니다. 만약 우리가 이 파드의 IP로 직접 통신한다면, 파드가 바뀔 때마다 접속 정보를 수정해야 하는 큰 문제가 발생합니다.

서비스는 이러한 문제를 해결하기 위해, 특정 **레이블(Label)**을 가진 파드 그룹을 찾아내어 이들을 대표하는 **고유한 가상 IP 주소(ClusterIP)**와 DNS 이름을 부여합니다. 이제 클라이언트(다른 파드 등)는 파드의 실제 IP가 아닌 서비스의 고정된 IP나 DNS 이름으로만 통신하면 됩니다. 서비스는 알아서 요청을 건강한 상태의 파드 중 하나에게 전달하며 로드 밸런싱 역할도 수행합니다.

핵심 기능: 파드 그룹에 대한 단일 진입점 제공 및 로드 밸런싱

연결 방식: 서비스는 **셀렉터(Selector)**를 사용해 특정 **레이블(Label)**을 가진 파드들을 자동으로 찾아내 연결합니다.

엔드포인트(Endpoints): 서비스에 연결된 파드들의 실제 IP 주소 목록은 **엔드포인트슬라이스(EndpointSlice)**라는 오브젝트에 의해 자동으로 관리됩니다. 파드가 죽거나 새로 생기면 이 목록은 즉시 업데이트됩니다.

2) 서비스 타입 (Service Types) നാല്
쿠버네티스는 사용 목적에 따라 4가지 종류의 서비스 타입을 제공합니다.


가. ClusterIP
정의: 쿠버네티스 클러스터 내부에서만 사용할 수 있는 가상 IP를 할당합니다. 서비스를 생성할 때 타입을 지정하지 않으면 기본값(Default)으로 사용됩니다.

주요 용도: 클러스터 내부의 마이크로서비스 간 통신에 사용됩니다. (예: 웹 애플리케이션 파드가 데이터베이스 파드에 접근할 때)

특징: 외부에서는 직접 접근할 수 없습니다.


나. NodePort
정의: 모든 워커 노드(Worker Node)의 특정 포트를 외부에 개방하고, 이 포트로 들어온 요청을 해당 서비스로 전달합니다. ClusterIP가 먼저 생성된 후 그 기능이 확장되는 방식입니다.

주요 용도: 개발이나 테스트 목적으로 서비스를 외부에 간단히 노출시키고 싶을 때 사용합니다.

특징: <Node의 IP 주소>:<NodePort> 형식으로 외부에서 접근할 수 있습니다.


다. LoadBalancer
정의: AWS, GCP, Azure 등 클라우드 플랫폼(Cloud Provider)의 로드 밸런서를 동적으로 생성하고 서비스에 연결합니다. NodePort와 ClusterIP가 먼저 생성된 후 기능이 확장됩니다.

주요 용도: 프로덕션 환경에서 서비스를 안정적으로 외부에 노출할 때 사용합니다.

특징: 클라우드 로드 밸런서가 제공하는 고유한 외부 IP 주소를 통해 서비스에 접근할 수 있습니다.


라. ExternalName
정의: 서비스에 IP 대신 example.com과 같은 외부 서비스의 DNS 이름을 CNAME 레코드처럼 매핑합니다.

주요 용도: 클러스터 내부의 파드가 외부 서비스를 마치 내부 서비스처럼 고정된 이름으로 호출하고 싶을 때 사용합니다. (예: 외부 데이터베이스나 API 서비스)

특징: 프록시나 로드 밸런싱 기능 없이 단순히 DNS 이름만 반환합니다.

| 타입 | 접근 범위 | 주요 사용 사례 |
|---|---|---|
| ClusterIP | 클러스터 내부 | 내부 마이크로서비스 간 통신 |
| NodePort | 클러스터 외부 | 개발 및 테스트용 외부 노출 |
| LoadBalancer | 클러스터 외부 | 프로덕션용 외부 서비스 노출 |
| ExternalName | 외부 서비스 | 내부에서 외부 서비스를 호출 |


3) 헤드리스 서비스 (Headless Service)
일반적인 서비스가 단일 가상 IP를 통해 파드들에게 요청을 분산하는 것과 달리, 헤드리스 서비스는 로드 밸런싱을 하지 않고 서비스에 연결된 모든 파드들의 실제 IP 목록을 직접 반환합니다.

설정 방법: 서비스 YAML 파일에서 spec.clusterIP 필드 값을 None으로 설정합니다.

주요 용도: 각 파드와 개별적으로 통신해야 하는 Stateful 애플리케이션(예: 데이터베이스 클러스터) 환경에서 주로 사용됩니다. 클라이언트는 서비스의 DNS 이름을 질의하여 모든 멤버 파드의 IP를 알아낸 후, 자신이 원하는 특정 파드에 직접 접속할 수 있습니다.

4) 서비스와 Kube-proxy 🌐
Kube-proxy는 클러스터의 모든 노드에서 실행되는 데몬으로, 서비스의 네트워킹을 실제로 구현하는 역할을 담당합니다.

kube-proxy는 마스터 노드의 API 서버를 계속 감시하다가, 새로운 서비스나 엔드포인트슬라이스가 생성/변경되면 각 노드의 네트워크 규칙(iptables, IPVS 등)을 업데이트합니다. 이 규칙 덕분에 특정 서비스의 가상 IP(ClusterIP)로 향하는 트래픽이 실제 파드의 IP로 정확하게 전달될 수 있는 것입니다. 즉, 서비스가 "무엇을 할지"를 정의한다면, kube-proxy는 그 정의를 보고 "어떻게 할지"를 각 노드에 실제로 설정하는 실행자입니다.

--------------------------------------------------------------------------

1) 디플로이먼트(Deployment)의 이론적 역할: 상태 관리자 🧑‍🔧
디플로이먼트의 핵심 역할은 애플리케이션(파드 그룹)이 우리가 원하는 상태(Desired State)를 항상 유지하도록 보장하는 것입니다. 디플로이먼트는 애플리케이션의 생명주기(Lifecycle) 전체를 책임집니다.

선언적 모델 (Declarative Model)
사용자는 "nginx 1.14 버전 컨테이너를 3개 실행시켜줘" 와 같이 '원하는 최종 상태'를 YAML 파일에 선언합니다. 그러면 디플로이먼트 컨트롤러는 현재 상태를 지속적으로 감시하며, 만약 현재 상태가 선언된 상태와 다르면 이를 맞추기 위해 필요한 작업을 자동으로 수행합니다.

자동 복구 (Self-Healing)
만약 3개의 파드 중 하나가 죽거나, 파드가 실행 중이던 노드(Node)에 장애가 발생하면 디플로이먼트는 이를 즉시 감지합니다. 그리고 원하는 상태인 '3개'를 맞추기 위해 자동으로 새로운 파드를 생성하여 대체합니다. 이를 통해 애플리케이션의 안정성과 가용성을 보장합니다.

확장성 (Scalability)
트래픽이 증가하여 더 많은 파드가 필요해지면, 사용자는 replicas 값을 3에서 5로 변경하기만 하면 됩니다. 디플로이먼트는 이 선언을 보고 즉시 2개의 파드를 추가로 생성하여 확장(Scale-out)을 완료합니다.

무중단 업데이트 (Rolling Updates)
애플리케이션을 신규 버전(예: nginx 1.15)으로 업데이트할 때, 디플로이먼트는 구버전 파드를 한 번에 모두 삭제하는 대신, 신규 버전 파드를 하나씩 점진적으로 추가하고 구버전 파드를 제거합니다. 이 과정 덕분에 사용자는 서비스 중단 없이 안전하게 애플리케이션을 업데이트할 수 있습니다. 문제가 발생하면 이전 버전으로 롤백(Rollback)하는 기능도 내장되어 있습니다.

2) 서비스(Service)의 이론적 역할: 안정적인 중개자 ☎️
서비스의 핵심 역할은 동적으로 변하는 파드들에게 안정적이고 단일화된 네트워크 진입점(Endpoint)을 제공하는 것입니다. 서비스는 '어떻게 애플리케이션을 찾고 통신할 것인가'의 문제를 해결합니다.

추상화 (Abstraction)
서비스는 여러 파드들의 집합을 대표하는 하나의 가상 계층입니다. 클라이언트(다른 파드나 사용자)는 개별 파드의 IP 주소나 생명주기에 대해 전혀 알 필요가 없습니다. 클라이언트는 오직 서비스가 제공하는 고정된 가상 IP(ClusterIP)와 DNS 이름만 알고 통신하면 됩니다.

서비스 디스커버리 (Service Discovery)
클러스터 내의 어떤 애플리케이션이 다른 애플리케이션과 통신하고 싶을 때, IP 주소를 하드코딩하는 대신 서비스의 고유 DNS 이름(예: ser-nginx.default.svc.cluster.local)을 호출하기만 하면 됩니다. 쿠버네티스 내부 DNS 시스템이 이 이름을 서비스의 가상 IP로 자동 변환해주므로, 애플리케이션을 쉽게 찾을 수 있습니다.

로드 밸런싱 (Load Balancing)
서비스는 자신에게 들어온 요청을 셀렉터(Selector)와 일치하는 레이블(Label)을 가진 여러 파드들에게 자동으로 분산합니다. 이를 통해 특정 파드에 트래픽이 몰리는 것을 방지하고 전체적인 부하를 균등하게 유지합니다.

결론: 왜 이 둘을 분리했을까?
"애플리케이션을 어떻게 실행하고 업데이트할 것인가(디플로이먼트)의 문제와, 그 애플리케이션에 어떻게 접속할 것인가(서비스)의 문제를 완전히 분리하여 서로에게 미치는 영향을 최소화하기 위함입니다."

이러한 관심사의 분리(Separation of Concerns) 덕분에, 개발자는 배후에서 디플로이먼트를 통해 자유롭게 애플리케이션을 확장하거나, 업데이트하거나, 심지어 완전히 다른 버전으로 교체할 수 있습니다. 그동안 클라이언트는 아무런 변경 없이 동일한 서비스 주소로 계속해서 안정적으로 요청을 보낼 수 있습니다. 이 느슨한 결합(Loose Coupling)이 쿠버네티스를 유연하고 탄력적인 시스템으로 만드는 핵심 철학입니다

| 구분 | 디플로이먼트 (Deployment) | 서비스 (Service) |
|---|---|---|
| 역할 | 애플리케이션 실행 및 상태 관리 | 애플리케이션에 대한 네트워크 접근 제공 | 
| 관심사 | 파드의 생명주기 (생성, 복제, 업데이트, 복구) | 고정된 주소, 트래픽 분산, 외부 노출 | 
| 핵심 기능 | 자동 복구, 롤링 업데이트, 확장 | 서비스 디스커버리, 로드 밸런싱 |

--------------------------------------------------------------------------

## 🚀 ClusterIP 서비스 실습: 클러스터 내부 통신의 중심 만들기
#### 🎯 목표: 여러 개의 파드(Pod)를 대표하는 **하나의 고정된 내부 IP(ClusterIP)**를 가진 서비스를 생성합니다. 이 서비스를 통해 클러스터 내부에서 안정적으로 애플리케이션에 접근하고, 서비스의 자동 로드 밸런싱 동작 원리를 직접 확인하는 것을 목표로 합니다.

#### 💡 핵심 개념: ClusterIP는 쿠버네티스 서비스의 기본 타입으로, 클러스터 내부에서만 접근 가능한 고유한 가상 IP를 제공합니다. 외부에는 노출되지 않기 때문에 데이터베이스나 내부 API 서버처럼 클러스터 내의 다른 애플리케이션들만 안전하게 호출해야 하는 백엔드 서비스에 주로 사용됩니다.

단계별 실습
1) 애플리케이션 배포 (Deployment 생성)
먼저, 서비스를 통해 노출시킬 3개의 Nginx 파드를 생성하는 디플로이먼트를 배포합니다. 이 파드들은 모두 app: nginx라는 공통된 이름표(Label)를 가집니다.

vi dep-nginx.yaml
YAML
```
# dep-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dep-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14
        ports:
        - containerPort: 80
```

디플로이먼트 생성 및 확인:
Bash
```
# 디플로이먼트를 생성합니다.
kubectl apply -f dep-nginx.yaml

# 3개의 파드가 정상적으로 실행 중인지 확인합니다. 각 파드의 IP 주소도 확인해두세요.
kubectl get pods -l app=nginx -o wide
```

2) ClusterIP 서비스 생성
이제 app: nginx 레이블을 가진 파드들을 바라보는 ClusterIP 타입의 서비스를 생성합니다.

vi service-clusterip.yaml
YAML
```
# service-clusterip.yaml
apiVersion: v1
kind: Service
metadata:
  name: clusterip-service
spec:
  # type: ClusterIP  <-- ClusterIP는 기본값이므로 생략해도 무방합니다.
  # clusterIP: 10.99.0.1 <-- 특정 IP를 지정할 수 있지만, 보통은 자동 할당되도록 비워둡니다.
  selector:
    app: nginx # 'app=nginx' 레이블을 가진 파드를 찾아 연결합니다.
  ports:
  - protocol: TCP
    port: 80 # 서비스 자체의 포트
    targetPort: 80 # 파드의 컨테이너 포트
```

서비스 생성 및 확인:
Bash
```
# 서비스를 생성합니다.
kubectl apply -f service-clusterip.yaml

# 서비스가 생성되고 고유한 CLUSTER-IP를 할당받았는지 확인합니다.
kubectl get service clusterip-service
```

3) 서비스 상세 정보 및 엔드포인트 확인
서비스가 어떤 파드들을 바라보고 있는지 상세 정보를 통해 확인합니다. Endpoints 항목에 위에서 생성한 파드 3개의 IP 주소가 모두 표시되는지 확인하는 것이 중요합니다.
Bash
```
kubectl describe svc clusterip-service
```

4) 서비스 접속 테스트
ClusterIP는 클러스터 내부 IP이므로, 클러스터 내부에서만 접속할 수 있습니다. 테스트를 위해 임시 파드를 하나 실행하여 curl 명령어로 서비스에 접근해 보겠습니다.
Bash
```
# 테스트용 임시 파드를 실행하고 셸에 접속합니다.
kubectl run tmp --rm -it --image=busybox --restart=Never -- sh

# 파드 셸 안에서 아래 명령어를 실행합니다.
# CLUSTER_IP 부분은 위에서 확인한 서비스의 IP 주소로 변경하세요.
curl <CLUSTER_IP>

# Nginx 시작 페이지가 보이면 성공입니다. 확인 후 'exit'를 입력해 빠져나옵니다.
exit
```

5) [심화] 로드 밸런싱 동작 확인 (tcpdump)
서비스가 어떻게 요청을 여러 파드에게 분산하는지 tcpdump를 이용해 네트워크 패킷을 직접 관찰해 보겠습니다. (터미널 2개가 필요합니다.)

첫 번째 터미널 - 패킷 감시:
tcpdump를 실행하여 80번 포트로 향하는 TCP 패킷을 감시합니다. ens33 부분은 자신의 네트워크 인터페이스 이름(예: eth0)으로 변경해야 할 수 있습니다.
Bash
```
# -n 옵션은 IP 주소를 이름으로 변환하지 않아 더 명확하게 보여줍니다.
sudo tcpdump -i ens33 -n tcp dst port 80
```

두 번째 터미널 - 반복 요청:
for 루프를 이용해 서비스에 10번의 요청을 연속으로 보냅니다.
Bash
```
# CLUSTER_IP 부분은 서비스의 IP 주소로 변경하세요.
for i in {1..10}; do curl <CLUSTER_IP>; sleep 0.5; done
```
        결과 확인:
        두 번째 터미널에서 요청을 보내는 동안, 첫 번째 터미널의 tcpdump 출력 화면을 보세요. 목적지(dst) IP가 우리가 요청한 서비스 IP가 아니라, 디플로이먼트가 생성한 실제 파드들의 IP 주소들로 계속 바뀌면서 나타나는 것을 볼 수 있습니다. 이것이 바로 서비스의 로드 밸런싱이 동작하는 증거입니다.

6) 실습 마무리 (리소스 정리)
실습에 사용된 서비스와 디플로이먼트를 모두 삭제하여 환경을 정리합니다.
Bash
```
kubectl delete svc clusterip-service
kubectl delete deploy dep-nginx
```

--------------------------------------------------------------------------

## 🚀 NodePort 서비스 실습: 클러스터 외부로 애플리케이션 노출하기
#### 🎯 목표: ClusterIP를 기반으로 각 노드(Node)의 특정 포트를 개방하는 NodePort 타입의 서비스를 생성합니다. 이를 통해 클러스터 외부에서 애플리케이션에 직접 접근하는 방법을 배우고, 외부 트래픽이 어떻게 내부 파드까지 전달되는지 그 과정을 이해하는 것을 목표로 합니다.

#### 💡 핵심 개념: NodePort는 개발이나 테스트 환경에서 서비스를 외부에 간단히 노출시킬 때 유용한 서비스 타입입니다. 서비스를 생성하면, 쿠버네티스는 모든 워커 노드의 특정 포트(기본 범위: 30000-32767)를 예약합니다. 외부 사용자는 <아무 노드의 IP>:<예약된 포트>로 접속할 수 있으며, 해당 노드는 이 요청을 서비스의 ClusterIP로 전달하여 최종적으로 파드에게 트래픽을 보냅니다.

중요: NodePort 서비스는 내부 통신을 위한 ClusterIP를 먼저 생성한 후, 그 위에 외부 접근 기능을 추가하는 방식으로 동작합니다.

단계별 실습
1. 애플리케이션 배포 (Deployment 생성)
먼저, 외부로 노출시킬 3개의 Nginx 파드를 생성하는 디플로이먼트를 배포합니다. (이전 ClusterIP 실습과 동일한 파일입니다.)

vi dep-nginx.yaml
YAML
```
# dep-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dep-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14
        ports:
        - containerPort: 80
```

디플로이먼트 생성:
Bash
```
kubectl apply -f dep-nginx.yaml
```

2) NodePort 서비스 생성
app: nginx 레이블을 가진 파드들을 외부로 노출시킬 NodePort 타입의 서비스를 생성합니다. nodePort: 30000으로 특정 포트를 지정했지만, 이 부분을 생략하면 쿠버네티스가 30000-32767 범위 내에서 임의의 포트를 자동 할당합니다.

vi service-nodeport.yaml
YAML
```
# service-nodeport.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-nodeport
spec:
  type: NodePort # 타입을 NodePort로 명시합니다.
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80         # ClusterIP가 사용할 포트
    targetPort: 80   # 파드의 컨테이너 포트
    nodePort: 30000  # 외부로 노출될 노드의 포트
```

서비스 생성:
Bash
```
kubectl apply -f service-nodeport.yaml
```

3) 서비스 상태 확인
서비스가 생성되면 TYPE이 NodePort로 표시되고, PORT(S) 항목에 ClusterIP 포트와 NodePort가 함께 매핑되어(80:30000/TCP) 나타나는 것을 확인할 수 있습니다.
Bash
```
# -o wide 옵션을 추가하면 Selector 정보도 함께 볼 수 있습니다.
kubectl get service service-nodeport -o wide
```

서비스 상세 정보 확인:
describe 명령어로 ClusterIP와 NodePort, 그리고 트래픽을 전달받을 파드들의 IP 목록(Endpoints)을 모두 확인합니다.
Bash
```
kubectl describe svc service-nodeport
```

4) 서비스 접속 테스트
NodePort 서비스는 내부(ClusterIP)와 외부(NodePort) 양쪽에서 모두 접근할 수 있습니다.

A. 내부 접근 (ClusterIP를 통한 테스트)
먼저, 서비스의 ClusterIP로 이전과 같이 내부 통신이 잘 되는지 확인합니다.
Bash
```
kubectl run tmp --rm -it --image=busybox --restart=Never -- sh

# CLUSTER_IP 부분은 위에서 확인한 서비스의 IP로 변경하세요.
curl <CLUSTER_IP>
wget -O - -q <CLUSTER_IP>
```

B. 외부 접근 (NodePort를 통한 테스트)
이제 **클러스터 외부 환경(예: 로컬 PC 터미널)**에서 각 노드의 IP와 지정된 NodePort(30000)로 접속합니다. 어떤 노드의 IP로 접속해도 동일하게 Nginx 시작 페이지가 보여야 합니다.
Bash
```
# Node1으로 접속
curl http://10.10.8.104:30000

# Node2로 접속
curl http://10.10.8.105:30000

# Node3으로 접속
curl http://10.10.8.106:30000
```
        ✨ 핵심 포인트: 어느 노드로 요청을 보내든, 해당 노드의 kube-proxy가 요청을 받아 서비스에 연결된 3개의 파드 중 하나로 트래픽을 전달해줍니다.

5) [심화] 외부 트래픽 흐름 확인 (tcpdump)
외부에서 들어온 요청이 어떻게 파드까지 전달되는지 네트워크 패킷을 추적해 보겠습니다. (마스터 노드에서 터미널 2개가 필요합니다.)

첫 번째 터미널 - 패킷 감시:
NodePort인 30000번 포트로 들어오는 패킷을 감시합니다.
Bash
```
sudo tcpdump -i any -n tcp port 30000
```

두 번째 터미널 - 외부에서 요청 보내기:
for 루프를 이용해 3개의 노드에 순서대로 요청을 보냅니다.
Bash
```
# 3개의 노드에 차례대로 curl 요청을 보냅니다.
for i in 4 5 6; do curl http://10.10.8.10$i:30000; sleep 1; done
```

        결과 확인:
        두 번째 터미널에서 요청을 보낼 때, 첫 번째 터미널의 tcpdump 화면을 보세요. 외부 IP에서 각 노드의 30000번 포트로 패킷이 들어오는 것을 확인할 수 있습니다. 이 패킷은 이후 kube-proxy에 의해 실제 파드의 80번 포트로 전달됩니다.

6) 실습 마무리 (리소스 정리)
실습에 사용된 서비스와 디플로이먼트를 모두 삭제하여 환경을 정리합니다.
Bash
```
kubectl delete svc service-nodeport
kubectl delete deploy dep-nginx
```

--------------------------------------------------------------------------

## 🚀 LoadBalancer 서비스 실습: 클라우드 환경의 표준 외부 노출
#### 🎯 목표: 클라우드 환경에서 서비스를 외부에 노출하는 표준 방식인 LoadBalancer 타입의 서비스를 생성해봅니다. 이를 통해 클라우드가 아닌 환경에서는 EXTERNAL-IP가 <pending> 상태에 머무르는 것을 직접 확인하고, 그 이유를 이해하는 것을 목표로 합니다.

#### 💡 핵심 개념: LoadBalancer 서비스는 클라우드 플랫폼의 로드 밸런서를 자동으로 프로비저닝(생성 및 설정)하여 서비스에 연결하는 가장 안정적이고 효율적인 외부 노출 방식입니다. 생성 과정에서 NodePort와 ClusterIP도 함께 만들어지며, 클라우드 로드 밸런서는 각 노드의 NodePort로 트래픽을 분산시켜 최종적으로 파드에 전달합니다.

## ⚠️ 중요: 실습 환경에 대한 사전 안내
type: LoadBalancer 서비스는 AWS, GCP, Azure와 같은 클라우드 플랫폼 환경과 연동하여 동작하는 것을 전제로 합니다. 서비스를 생성하면 쿠버네티스는 클라우드 플랫폼에 "외부와 연결될 Load Balancer를 하나 만들어주고 외부 IP 주소를 할당해줘" 라고 자동으로 요청합니다.

만약 지금 사용하시는 환경이 클라우드 플랫폼이 아닌 직접 구축한 온프레미스(On-premise) 환경이라면, 이 요청을 처리해 줄 대상이 없기 때문에 서비스의 EXTERNAL-IP가 영원히 <pending> 상태로 남아있게 됩니다.

결론: 지금 환경에서는 이 실습이 정상적으로 동작하지 않으며, EXTERNAL-IP가 할당되지 않는 <pending> 상태를 확인하는 것 자체가 이번 실습의 핵심 학습 목표입니다. (온프레미스 환경에서 이를 동작시키려면 MetalLB와 같은 별도의 솔루션을 설치해야 합니다.)


단계별 실습
1. 애플리케이션 배포 (Deployment 생성)
먼저, 외부로 노출시킬 3개의 Nginx 파드를 생성하는 디플로이먼트를 배포합니다. (이전 실습과 동일)

vi dep-nginx.yaml
YAML
```
# dep-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dep-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14
        ports:
        - containerPort: 80
```

디플로이먼트 생성:
Bash
```
kubectl apply -f dep-nginx.yaml
```
2) LoadBalancer 서비스 생성
type: LoadBalancer로 서비스를 정의합니다. 쿠버네티스는 이 YAML을 보고 연동된 외부 솔루션(클라우드 컨트롤러 등)에게 외부 IP 할당을 요청하게 됩니다.

vi service-lb.yaml
YAML
```
# service-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-loadbalancer
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

서비스 생성:
Bash
```
kubectl apply -f service-lb.yaml
```
3) 서비스 상태 확인 (On-Premise 환경)
서비스를 조회하여 EXTERNAL-IP 상태를 확인합니다. 클라우드 연동이 없는 환경이므로, IP가 할당되지 못하고 <pending> 상태로 계속 대기하게 됩니다.
Bash
```
# EXTERNAL-IP가 <pending> 상태인 것을 확인합니다.
kubectl get service service-loadbalancer
```

watch 명령어를 사용하면 상태가 변하지 않고 계속 대기 중인 것을 실시간으로 확인할 수 있습니다.
Bash
```
# 1초마다 상태를 갱신하여 보여줍니다. (종료는 Ctrl+C)
watch kubectl get service service-loadbalancer
```

4) 클라우드 환경에서의 동작 (이론)
만약 이 실습을 AWS(EKS), GCP(GKE), Azure(AKS)와 같은 클라우드 환경에서 진행했다면, 몇 분 안에 다음과 같은 일이 일어납니다.

클라우드 플랫폼에서 자동으로 외부용 로드 밸런서(예: AWS의 ELB)가 생성됩니다.

로드 밸런서에 공인 IP 주소가 할당됩니다.

EXTERNAL-IP 필드에 <pending> 대신 할당된 공인 IP 주소가 표시됩니다.

사용자는 curl http://<할당받은-외부-IP> 명령어로 어디서든 서비스에 접속할 수 있게 됩니다.

5) 실습 마무리 (리소스 정리)
실습에 사용된 서비스와 디플로이먼트를 모두 삭제하여 환경을 정리합니다.

Bash
```
kubectl delete svc service-loadbalancer
kubectl delete deploy dep-nginx
```

--------------------------------------------------------------------------

## 🚀 LoadBalancer 서비스 실습 (개선판): 클라우드 환경의 표준 외부 노출
#### 🎯 목표: 클라우드 환경에서 서비스를 외부에 노출하는 표준 방식인 LoadBalancer 타입의 서비스를 생성합니다. 이를 통해 클라우드가 아닌 환경에서는 EXTERNAL-IP가 <pending> 상태에 머무르는 것을 직접 확인하고, 그 이유를 이해하는 것을 목표로 합니다.

#### 💡 핵심 개념: LoadBalancer 서비스는 클라우드 플랫폼의 로드 밸런서를 자동으로 프로비저닝(생성 및 설정)하여 서비스에 연결하는 가장 안정적이고 효율적인 외부 노출 방식입니다. 생성 과정에서 NodePort와 ClusterIP도 함께 만들어지며, 클라우드 로드 밸런서는 각 노드의 NodePort로 트래픽을 분산시켜 최종적으로 파드에 전달합니다.

## ⚠️ 중요: 실습 환경에 대한 사전 안내
type: LoadBalancer 서비스는 AWS, GCP, Azure와 같은 클라우드 플랫폼 환경과 연동하여 동작하는 것을 전제로 합니다. 서비스를 생성하면 쿠버네티스는 클라우드 플랫폼에 "외부와 연결될 Load Balancer를 하나 만들어주고 외부 IP 주소를 할당해줘" 라고 자동으로 요청합니다.

만약 지금 사용하시는 환경이 클라우드 플랫폼이 아닌 직접 구축한 온프레미스(On-premise) 환경이라면, 이 요청을 처리해 줄 대상이 없기 때문에 서비스의 EXTERNAL-IP가 영원히 <pending> 상태로 남아있게 됩니다.

결론: 지금 환경에서는 이 실습이 정상적으로 동작하지 않으며, EXTERNAL-IP가 할당되지 않는 <pending> 상태를 확인하는 것 자체가 이번 실습의 핵심 학습 목표입니다.

단계별 실습
1) 애플리케이션 배포 (Deployment 생성)
먼저, 외부로 노출시킬 3개의 Nginx 파드를 생성하는 디플리먼트를 배포합니다. (이전 실습과 동일)

vi dep-nginx.yaml
YAML
```
# dep-nginx.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dep-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14
        ports:
        - containerPort: 80
```

디플리먼트 생성:
Bash
```
kubectl apply -f dep-nginx.yaml
```

2) LoadBalancer 서비스 생성
type: LoadBalancer로 서비스를 정의합니다.

vi service-lb.yaml
YAML
```
# service-lb.yaml
apiVersion: v1
kind: Service
metadata:
  name: service-loadbalancer
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80        # 로드밸런서가 외부 요청을 받을 포트 (서비스의 포트)
    targetPort: 80  # 요청을 최종적으로 전달할 파드의 컨테이너 포트
```
        ✨ 핵심 포인트: LoadBalancer 타입을 생성하면, 외부 로드밸런서와 클러스터 내부를 연결하기 위한 NodePort가 배경에서 자동으로 할당됩니다. 하지만 최종 사용자는 이 NodePort를 직접 사용할 필요 없이 EXTERNAL-IP로만 접근하면 됩니다.

서비스 생성:
Bash
```
kubectl apply -f service-lb.yaml
```

3) 서비스 상태 확인 (On-Premise 환경)
서비스를 조회하여 EXTERNAL-IP 상태를 확인합니다. 클라우드 연동이 없는 환경이므로, IP가 할당되지 못하고 <pending> 상태로 계속 대기하게 됩니다.

kubectl의 내장 기능인 -w (--watch) 플래그를 사용하면 상태 변화를 실시간으로 감시할 수 있습니다.
Bash
```
# EXTERNAL-IP가 <pending> 상태로 계속 유지되는 것을 실시간으로 확인합니다.
# 종료는 Ctrl+C를 누르세요.
kubectl get svc service-loadbalancer -w
```

4) 클라우드 환경에서의 동작 (이론)
만약 이 실습을 AWS(EKS), GCP(GKE), Azure(AKS)와 같은 클라우드 환경에서 진행했다면, 몇 분 안에 다음과 같은 일이 일어납니다.

클라우드 플랫폼에서 자동으로 외부용 로드 밸런서(예: AWS의 ELB)가 생성됩니다.

로드 밸런서에 공인 IP 주소가 할당됩니다.

EXTERNAL-IP 필드에 <pending> 대신 할당된 공인 IP 주소가 표시됩니다.

사용자는 curl http://<할당받은-외부-IP> 명령어로 어디서든 서비스에 접속할 수 있게 됩니다.

5) 실습 마무리 (리소스 정리)
실습에 사용된 서비스와 디플리먼트를 모두 삭제하여 환경을 정리합니다.
Bash
```
kubectl delete -f service-lb.yaml
kubectl delete -f dep-nginx.yaml
```

## 📌 정리 및 다음 단계
이번 실습을 통해 LoadBalancer 서비스는 클라우드 플랫폼과의 연동이 필수적이라는 점을 확인했습니다.

만약 현재 사용 중인 온프레미스 환경에서 실제로 LoadBalancer 기능을 구현하고 싶다면, MetalLB와 같은 솔루션을 클러스터에 추가로 설치해야 합니다. MetalLB는 온프레미스 환경에서도 EXTERNAL-IP를 할당해주는 역할을 수행합니다.

--------------------------------------------------------------------------

## 1) MetalLB 이론: 온프레미스 환경의 LoadBalancer
### 가. MetalLB란?
쿠버네티스에서 type: LoadBalancer 서비스는 AWS, GCP 같은 클라우드 환경에서 제공하는 로드밸런서와 연동하는 것을 전제로 합니다. 따라서 일반 서버나 가상머신으로 직접 구축한 온프레미스(On-premise) 또는 베어메탈(Bare-metal) 환경에서는 이 기능을 처리해 줄 대상이 없어 EXTERNAL-IP가 영원히 <pending> 상태에 머물게 됩니다.

MetalLB는 바로 이 문제를 해결해주는 오픈소스 프로젝트입니다. 온프레미스 환경에서도 type: LoadBalancer 서비스를 생성하면, MetalLB가 미리 지정된 IP 주소 풀에서 외부 IP를 할당해주어 마치 클라우드 환경처럼 서비스를 외부로 노출할 수 있게 해줍니다.

### 나. 동작 방식 (Modes)
MetalLB는 표준 네트워크 프로토콜을 사용하여 IP 주소를 외부에 알리는 두 가지 모드를 제공합니다.

Layer 2 모드 (실습에서 사용할 방식)

원리: 서비스가 생성되면, 클러스터의 노드 중 하나가 대표로 서비스의 외부 IP 주소를 가져갑니다. 이 노드는 ARP 프로토콜을 통해 로컬 네트워크에 "이 IP 주소(192.168.108.100)는 내 MAC 주소로 와야 해!"라고 알립니다. 그러면 공유기의 모든 트래픽이 해당 대표 노드로 오게 되고, 그 노드가 다시 내부 파드들에게 트래픽을 분산시킵니다.

장점: 별도의 네트워크 장비 설정 없이 간단하게 구성할 수 있습니다.

단점: 모든 트래픽이 대표 노드 하나를 거치므로 병목이 될 수 있으며, 대표 노드에 장애가 발생하면 다른 노드가 역할을 넘겨받기까지 수 초의 장애 시간이 발생합니다.

BGP 모드 (BGP Mode)

원리: BGP 프로토콜을 지원하는 라우터와 직접 통신하여 서비스의 외부 IP로 가는 경로를 네트워크에 알립니다. 이를 통해 트래픽이 여러 노드로 직접 분산될 수 있어 진정한 로드 밸런싱이 가능합니다.

장점: 높은 성능과 빠른 장애 복구가 가능하여 프로덕션 환경에 적합합니다.

단점: BGP를 지원하는 라우터가 필요하고 네트워크에 대한 전문 지식이 요구됩니다.

### 다. 사전 요구사항: strictARP 설정
kube-proxy가 IPVS 모드로 동작할 때, 커널의 기본 ARP 동작 방식(strictARP: false)은 서비스의 가상 IP에 대한 일부 ARP 요청을 무시할 수 있습니다. MetalLB의 Layer 2 모드가 정상적으로 동작하려면, kube-proxy의 ConfigMap에서 strictARP 값을 true로 설정하여 커널이 모든 ARP 요청에 올바르게 응답하도록 해야 합니다.

## 2. 🚀 MetalLB 실습: 온프레미스 환경에 LoadBalancer 날개 달아주기
1단계: 사전 요구사항 (strictARP 모드 활성화)
kube-proxy의 strictARP 설정을 확인하고 true로 변경합니다.
Bash
```
# 1. 현재 설정 확인 (대부분 false로 나옵니다)
kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP

# 2. sed 명령어를 이용해 false를 true로 변경하여 적용
kubectl get configmap kube-proxy -n kube-system -o yaml | \
sed -e "s/strictARP: false/strictARP: true/" | \
kubectl apply -f - -n kube-system

# 3. 변경된 설정 다시 확인
kubectl get configmap kube-proxy -n kube-system -o yaml | grep strictARP
```

2단계: MetalLB 설치
MetalLB 공식 매니페스트를 사용하여 클러스터에 설치합니다. 이 명령어는 metallb-system 네임스페이스와 함께 컨트롤러, 스피커(Speaker) 등 필요한 모든 구성요소를 배포합니다.
Bash
```
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.5/config/manifests/metallb-native.yaml
```

3단계: MetalLB IP 주소 풀(Pool) 설정
MetalLB가 서비스에 할당해 줄 IP 주소의 범위를 정의합니다. 이 IP들은 현재 사용 중인 로컬 네트워크 대역에 속해야 하며, 다른 장비나 DHCP 서버에서 사용하지 않는 비어있는 주소여야 합니다.

vi metallb-config.yaml
YAML
```
# metallb-config.yaml
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: default-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.108.100-192.168.108.110 # 서비스에 할당할 IP 주소 범위
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: default-l2
  namespace: metallb-system
spec:
  ipAddressPools:
  - default-pool
```

설정 적용:
Bash
```
kubectl apply -f metallb-config.yaml
```

4단계: 테스트용 애플리케이션 및 LoadBalancer 서비스 배포
이제 type: LoadBalancer 서비스를 생성하여 MetalLB가 실제로 외부 IP를 할당하는지 테스트합니다.

vi test-app.yaml
YAML
```
# test-app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dep-nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: service-loadbalancer
spec:
  type: LoadBalancer # 타입을 LoadBalancer로 지정
  selector:
    app: nginx      # app=nginx 레이블을 가진 파드를 찾음
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
```

애플리케이션 및 서비스 배포:
Bash
```
kubectl apply -f test-app.yaml
```

5단계: 결과 확인
서비스를 조회했을 때, 이전 실습과 달리 EXTERNAL-IP가 더 이상 <pending>이 아니고, 우리가 설정한 IP 풀 범위 내의 주소(예: 192.168.108.100)를 할당받은 것을 볼 수 있습니다.
Bash
```
# EXTERNAL-IP에 IP가 할당되었는지 확인
kubectl get svc service-loadbalancer

NAME                   TYPE           CLUSTER-IP      EXTERNAL-IP        PORT(S)        AGE
service-loadbalancer   LoadBalancer   10.101.99.123   192.168.108.100   80:30386/TCP   2m
```

외부 IP로 접속 테스트:
이제 할당받은 EXTERNAL-IP로 curl 요청을 보내 Nginx 시작 페이지가 보이는지 확인합니다.
Bash
```
# 192.168.108.100 부분은 위에서 할당받은 실제 IP로 변경하세요.
curl http://192.168.108.100
```
6단계: 실습 마무리 (리소스 정리)
Bash
```
kubectl delete -f test-app.yaml
kubectl delete -f metallb-config.yaml
kubectl delete -f https://raw.githubusercontent.com/metallb/metallb/v0.14.5/config/manifests/metallb-native.yaml
```

--------------------------------------------------------------------------

